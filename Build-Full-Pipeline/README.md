Absolutely! Iâ€™ve converted your **corrected end-to-end CI/CD plan with Kubernetes, EC2, Docker, ECR, and GitHub self-hosted runner** into a polished `README.md` in the same professional format as your reference. Hereâ€™s the full version:

---

# ğŸš€ Project: End-to-End CI/CD Pipeline with Kubernetes on AWS

## ğŸ¯ Introduction

This project demonstrates a **complete DevOps workflow** using **Docker, Kubernetes (Kind), AWS EC2 & ECR, and GitHub Actions**.
A multi-service application (frontend, backend, MongoDB) is containerized, deployed to a **local Kubernetes cluster on EC2**, and managed via a **CI/CD pipeline**.

Every push to the `main` branch:

* Builds Docker images for frontend and backend
* Pushes images to Amazon ECR
* Updates deployments in Kubernetes cluster automatically via GitHub Actions

---

## ğŸŒ End Result

âœ… Fully automated deployment of multi-service application on AWS EC2
âœ… Kubernetes cluster managed via Kind
âœ… CI/CD pipeline using GitHub Actions and a self-hosted runner
âœ… Dockerized frontend (Nginx + HTML) and backend (Flask)
âœ… MongoDB service running inside cluster
âœ… Application accessible via EC2 public IP on port **30080**

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ README.md
â”œâ”€â”€ backend
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ nginx.conf
â”œâ”€â”€ k8s
â”‚   â”œâ”€â”€ backend-deployment.yaml
â”‚   â”œâ”€â”€ frontend-deployment.yaml
â”‚   â””â”€â”€ mongo-deployment.yaml
â”œâ”€â”€ kind-cluster.yaml
â””â”€â”€ .github
    â””â”€â”€ workflows
        â””â”€â”€ cicd.yaml
```

---

## ğŸ§  Application Overview

### ğŸ–¥ Frontend

* **Tech:** Nginx + HTML
* **Service Type:** NodePort
* Communicates with backend using Kubernetes DNS: `http://backend-service:5000`

### âš™ Backend

* **Tech:** Python + Flask
* **Service Type:** ClusterIP
* Connects to MongoDB via environment variables

### ğŸ—„ Database

* **Tech:** MongoDB
* **Service Type:** ClusterIP
* Ephemeral storage (no persistent volume yet)

---

## ğŸ³ Step 1 â€“ EC2 & Kubernetes Setup

### EC2 Configuration

* Amazon Linux 2023 (or Amazon Linux 2)
* Instance type: `t2.medium`
* Security Group:

  * SSH â†’ 22
  * Application â†’ 30080 (NodePort)

```bash
sudo dnf update -y
sudo dnf install -y docker git curl
sudo systemctl start docker
sudo usermod -aG docker ec2-user
newgrp docker
```

### Install kubectl

```bash
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
chmod +x kubectl
sudo mv kubectl /usr/local/bin/
kubectl version --client
```

### Install Kind

```bash
curl -Lo kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x kind
sudo mv kind /usr/local/bin/
```

### Create Kubernetes Cluster

```bash
kind create cluster --name multi-service --config kind-cluster.yaml
kubectl get nodes
```

Export kubeconfig for GitHub runner:

```bash
kind get kubeconfig --name multi-service > ~/.kube/config
export KUBECONFIG=~/.kube/config
```

âœ… Cluster name: `multi-service`
âœ… NodePort mapped: `30080`

---

## â˜ï¸ Step 2 â€“ AWS ECR Setup

### Configure AWS CLI

```bash
aws configure
```

### Create Repositories

```bash
aws ecr create-repository --repository-name backend-service
aws ecr create-repository --repository-name frontend-service
```

### Login to ECR

```bash
aws ecr get-login-password --region <AWS_REGION> \
| docker login --username AWS --password-stdin <AWS_ACCOUNT_ID>.dkr.ecr.<AWS_REGION>.amazonaws.com
```

### Create Kubernetes Image Pull Secret

```bash
kubectl create secret docker-registry ecr-secret \
--docker-server=<AWS_ACCOUNT_ID>.dkr.ecr.<AWS_REGION>.amazonaws.com \
--docker-username=AWS \
--docker-password=$(aws ecr get-login-password --region <AWS_REGION>)
```

Use in deployments:

```yaml
imagePullSecrets:
  - name: ecr-secret
```

> âš ï¸ Do not hardcode AWS account ID; use GitHub secrets instead.

---

## ğŸ”‘ Step 3 â€“ GitHub Repository Secrets

Create the following **repository secrets**:

| Secret Name           | Description    |
| --------------------- | -------------- |
| AWS_ACCESS_KEY_ID     | AWS access key |
| AWS_SECRET_ACCESS_KEY | AWS secret key |

These are used by GitHub Actions to authenticate with AWS and ECR.

---

## âš™ Step 4 â€“ GitHub Self-Hosted Runner Setup

### Install Dependencies

```bash
sudo dnf install -y libicu krb5-libs zlib openssl-libs libcurl ca-certificates tar gzip --allowerasing
```

### Configure Runner

1. Go to GitHub â†’ Repo â†’ Settings â†’ Actions â†’ Runners â†’ New self-hosted runner â†’ Linux
2. Download and configure runner:

```bash
./config.sh --url https://github.com/<OWNER>/<REPO> --token <RUNNER_TOKEN>
```

3. Run as service:

```bash
./run.sh          # Test listener
sudo ./svc.sh install
sudo ./svc.sh start
sudo ./svc.sh status
```

Verify:

```bash
kubectl get nodes
```

---

## ğŸ³ Step 5 â€“ Build & Push Docker Images

### Backend

```bash
docker build -t backend-service:1.0 backend/
docker tag backend-service:1.0 <ECR_URI>/backend-service:1.0
docker push <ECR_URI>/backend-service:1.0
```

### Frontend

```bash
docker build -t frontend-service:1.0 frontend/
docker tag frontend-service:1.0 <ECR_URI>/frontend-service:1.0
docker push <ECR_URI>/frontend-service:1.0
```

`<ECR_URI>` = `<AWS_ACCOUNT_ID>.dkr.ecr.<AWS_REGION>.amazonaws.com`

---

## ğŸ— Step 6 â€“ Kubernetes Deployment

Apply manifests:

```bash
kubectl apply -f k8s/mongo-deployment.yaml
kubectl apply -f k8s/backend-deployment.yaml
kubectl apply -f k8s/frontend-deployment.yaml
```

Validate:

```bash
kubectl get pods
kubectl get svc
```

Access app:

```
http://<EC2_PUBLIC_IP>:30080
```

---

## ğŸ” Step 7 â€“ GitHub Actions Workflow

* Push code â†’ GitHub Actions â†’ Build Docker images â†’ Push to ECR â†’ Self-hosted Runner â†’ Update Kubernetes â†’ Pods restart â†’ App updated in browser.
* Workflow uses **repository secrets** for AWS authentication.
* `imagePullSecrets` ensures Kubernetes can pull private images from ECR.

---

## ğŸ§ª Step 8 â€“ Validation Commands

```bash
kubectl get pods
kubectl get svc
kubectl rollout status deployment backend
kubectl rollout status deployment frontend
kubectl logs <pod-name>
kubectl describe pod <pod-name>
```

---

## âœ… Summary

âœ” Built multi-service application (frontend + backend + MongoDB)
âœ” Dockerized services
âœ” Created Kubernetes cluster using Kind on EC2
âœ” Configured CI/CD with GitHub Actions and self-hosted runner
âœ” Pushed images to AWS ECR
âœ” Automated deployment to Kubernetes
âœ” Access via EC2 public IP

---

## ğŸ§‘â€ğŸ“ Learning Outcomes

* Kubernetes cluster setup on EC2 using Kind
* Multi-service container orchestration
* CI/CD pipelines with GitHub Actions
* AWS ECR integration
* Self-hosted GitHub runners
* Real-world DevOps automation

